{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os, sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter all positive images out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all positive #1 (活动性出血) images -- 429 total images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, glob\n",
    "pos_ind_df = pd.read_excel(r'C:\\Users\\wiqwe\\Desktop\\上交科研\\c活动性出血.xlsx')\n",
    "pos_ind_df.columns\n",
    "name_ind = pos_ind_df[[' 姓名','出血典型病变图片号码']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traverse all positive image folders\n",
    "import re\n",
    "folder_prefix = r'C:\\Users\\wiqwe\\Desktop\\上交科研\\出血'\n",
    "folders = glob.glob(os.path.join(folder_prefix,'*'))\n",
    "# print(folders)\n",
    "name_to_folder = {}\n",
    "\n",
    "def name_extract(folder):\n",
    "    pattern = re.compile('\\d{6,10}(.+)')\n",
    "    name = pattern.findall(folder)\n",
    "    name_to_folder[name[0]] = folder\n",
    "    return name\n",
    "\n",
    "names = [name_extract(i) for i in folders]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy selected images from patient's folder to dataset folder\n",
    "import shutil\n",
    "pos_img_index = 0\n",
    "POSITIVE_IMGS_FOLDER = r'C:\\Users\\wiqwe\\Desktop\\上交科研\\selected_positive_#1_imgs'\n",
    "def func(a):\n",
    "    name, img_inds = a.tolist()\n",
    "    if name.endswith('2'): name = name[:-1]\n",
    "#     print(name, img_inds,'|', type(img_inds), len(img_inds), 'called')\n",
    "    img_inds = img_inds.replace(' ', '').replace('，', ',').strip(',').replace('.',',').split(',')\n",
    "    name = name.strip()\n",
    "#     print(type(img_inds), img_inds)\n",
    "    \n",
    "    def copy_file_func(img_ind):\n",
    "        global pos_img_index\n",
    "        full_path = os.path.join(name_to_folder[name], img_ind + '.jpg')\n",
    "        print(full_path)\n",
    "        paste_path = os.path.join(POSITIVE_IMGS_FOLDER, str(pos_img_index) + '.jpg')\n",
    "        shutil.copyfile(full_path,paste_path)\n",
    "        pos_img_index += 1\n",
    "   \n",
    "    _ = [copy_file_func(i) for i in img_inds]\n",
    "#     print(name, img_inds)\n",
    "    \n",
    "_ = name_ind.apply(func, axis=1, raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all positive #2 (血管畸形) images -- 1169 total images\n",
    "pos_ind_df = pd.read_excel(r'C:\\Users\\wiqwe\\Desktop\\上交科研\\消化道出血病人表-血管畸形80.xlsx', dtype=str)\n",
    "pos_ind_df.columns\n",
    "name_ind = pos_ind_df[[' 姓名','病变图片编号']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy selected images from patient's folder to dataset folder\n",
    "import shutil\n",
    "pos_img_index = 429\n",
    "POSITIVE_IMGS_FOLDER = r'C:\\Users\\wiqwe\\Desktop\\上交科研\\selected_positive_#2_imgs'\n",
    "def func(a):\n",
    "    name, img_inds = a.tolist()\n",
    "    if type(img_inds) != str: return\n",
    "    print(name, img_inds, type(img_inds))\n",
    "    img_inds = img_inds.replace(' ', '').replace('，', ',').strip(',').replace('.',',').split(',')\n",
    "    name = name.strip()\n",
    "    print(type(img_inds), img_inds)\n",
    "    \n",
    "    def copy_file_func(img_ind):\n",
    "        global pos_img_index\n",
    "        full_path = os.path.join(name_to_folder[name], img_ind + '.jpg')\n",
    "        print(full_path)\n",
    "        paste_path = os.path.join(POSITIVE_IMGS_FOLDER, str(pos_img_index) + '.jpg')\n",
    "        shutil.copyfile(full_path,paste_path)\n",
    "        pos_img_index += 1\n",
    "   \n",
    "    _ = [copy_file_func(i) for i in img_inds]\n",
    "#     print(name, img_inds)\n",
    "    \n",
    "_ = name_ind.apply(func, axis=1, raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample negative images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get negative images -- 454 * num_per_folder\n",
    "import random\n",
    "import glob, os, shutil\n",
    "NEGATIVE_IMGS_FOLDER = r'C:\\Users\\wiqwe\\Desktop\\上交科研\\selected_negative_imgs'\n",
    "folder_prefix = r'C:\\Users\\wiqwe\\Desktop\\上交科研\\阴性'\n",
    "neg_img_index = 0\n",
    "num_per_folder = 5\n",
    "folders = glob.glob(os.path.join(folder_prefix,'*'))\n",
    "def copy_neg_image(image):\n",
    "    global neg_img_index\n",
    "    image_basename = os.path.basename(image)\n",
    "    paste_path = os.path.join(NEGATIVE_IMGS_FOLDER, str(neg_img_index) + '.jpg')\n",
    "    neg_img_index += 1\n",
    "#     print(image)\n",
    "    shutil.copyfile(image,paste_path)\n",
    "    \n",
    "for folder in folders:\n",
    "    images = glob.glob(os.path.join(folder, '*'))\n",
    "    if not images:\n",
    "        continue\n",
    "    elif len(images) > num_per_folder:\n",
    "        images = random.sample(images, num_per_folder)\n",
    "    for image in images:\n",
    "        copy_neg_image(image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365 64\n",
      "996 175\n",
      "1772 312\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "# split train and validation set (copy files to different folder)\n",
    "POSITIVE_1_IMGS_FOLDER = r'C:\\Users\\wiqwe\\Desktop\\上交科研\\selected_positive_#1_imgs'\n",
    "POSITIVE_1_IMGS_TRAIN_FOLDER = r'C:\\Users\\wiqwe\\Desktop\\上交科研\\selected_positive_#1_imgs_train'\n",
    "POSITIVE_1_IMGS_VALIDATION_FOLDER = r'C:\\Users\\wiqwe\\Desktop\\上交科研\\selected_positive_#1_imgs_validation'\n",
    "POSITIVE_2_IMGS_FOLDER = r'C:\\Users\\wiqwe\\Desktop\\上交科研\\selected_positive_#2_imgs'\n",
    "POSITIVE_2_IMGS_TRAIN_FOLDER = r'C:\\Users\\wiqwe\\Desktop\\上交科研\\selected_positive_#2_imgs_train'\n",
    "POSITIVE_2_IMGS_VALIDATION_FOLDER = r'C:\\Users\\wiqwe\\Desktop\\上交科研\\selected_positive_#2_imgs_validation'\n",
    "NEGATIVE_IMGS_FOLDER = r'C:\\Users\\wiqwe\\Desktop\\上交科研\\selected_negative_imgs'\n",
    "NEGATIVE_IMGS_TRAIN_FOLDER = r'C:\\Users\\wiqwe\\Desktop\\上交科研\\selected_negative_imgs_train'\n",
    "NEGATIVE_IMGS_VALIDATION_FOLDER = r'C:\\Users\\wiqwe\\Desktop\\上交科研\\selected_negative_imgs_validation'\n",
    "VALIDATION_RATIO = 0.15\n",
    "\n",
    "# split randomly\n",
    "positive_1_imgs = glob.glob(os.path.join(POSITIVE_1_IMGS_FOLDER,'*'))\n",
    "positive_1_validation_indices = random.sample(list(range(429)), int(VALIDATION_RATIO*429))\n",
    "positive_1_train_indices = list(filter(lambda x: x not in positive_1_validation_indices, list(range(429))))\n",
    "print(len(positive_1_train_indices), len(positive_1_validation_indices))\n",
    "\n",
    "positive_2_imgs = glob.glob(os.path.join(POSITIVE_1_IMGS_FOLDER,'*'))\n",
    "positive_2_validation_indices = random.sample(list(range(429, 1600)), int(VALIDATION_RATIO*1169))\n",
    "positive_2_train_indices = list(filter(lambda x: x not in positive_2_validation_indices, list(range(429, 1600))))\n",
    "print(len(positive_2_train_indices), len(positive_2_validation_indices))\n",
    "\n",
    "negative_imgs = glob.glob(os.path.join(POSITIVE_1_IMGS_FOLDER,'*'))\n",
    "negative_validation_indices = random.sample(list(range(429)), int(VALIDATION_RATIO*2084))\n",
    "negative_train_indices = list(filter(lambda x: x not in negative_validation_indices, list(range(2084))))\n",
    "print(len(negative_train_indices), len(negative_validation_indices))\n",
    "\n",
    "#TODO: FIVE FOLD CV\n",
    "\n",
    "# clear folder if already exsits\n",
    "# folder_collections = [POSITIVE_1_IMGS_TRAIN_FOLDER, \\\n",
    "#                        POSITIVE_1_IMGS_VALIDATION_FOLDER, \\\n",
    "#                        POSITIVE_2_IMGS_TRAIN_FOLDER,\n",
    "#                        POSITIVE_2_IMGS_VALIDATION_FOLDER, \\\n",
    "#                        NEGATIVE_IMGS_TRAIN_FOLDER, \\\n",
    "#                        NEGATIVE_IMGS_VALIDATION_FOLDER]\n",
    "# for current_folder in folder_collections:\n",
    "#     shutil.rmtree(current_folder)\n",
    "#     os.makedirs(current_folder)\n",
    "\n",
    "#save and copy\n",
    "def copy_train_validation_image(image_index, source_image_folder, des_image_folder):\n",
    "    source_path = os.path.join(source_image_folder, str(image_index) + '.jpg')\n",
    "    paste_path = os.path.join(des_image_folder, str(image_index) + '.jpg')\n",
    "#     print(image)\n",
    "    shutil.copyfile(source_path, paste_path)\n",
    "    \n",
    "for i in positive_1_train_indices:\n",
    "    copy_train_validation_image(i, POSITIVE_1_IMGS_FOLDER, POSITIVE_1_IMGS_TRAIN_FOLDER)\n",
    "for i in positive_1_validation_indices:\n",
    "    copy_train_validation_image(i, POSITIVE_1_IMGS_FOLDER, POSITIVE_1_IMGS_VALIDATION_FOLDER)\n",
    "for i in positive_2_train_indices:\n",
    "    copy_train_validation_image(i, POSITIVE_2_IMGS_FOLDER, POSITIVE_2_IMGS_TRAIN_FOLDER)\n",
    "for i in positive_2_validation_indices:\n",
    "    copy_train_validation_image(i, POSITIVE_2_IMGS_FOLDER, POSITIVE_2_IMGS_VALIDATION_FOLDER)\n",
    "for i in negative_train_indices:\n",
    "    copy_train_validation_image(i, NEGATIVE_IMGS_FOLDER, NEGATIVE_IMGS_TRAIN_FOLDER)\n",
    "for i in negative_validation_indices:\n",
    "    copy_train_validation_image(i, NEGATIVE_IMGS_FOLDER, NEGATIVE_IMGS_VALIDATION_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# image preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import PIL.Image\n",
    "import glob, os, shutil\n",
    "POSITIVE_1_IMGS_FOLDER = r'C:\\Users\\wiqwe\\Desktop\\上交科研\\selected_positive_#1_imgs'\n",
    "POSITIVE_1_IMGS_TRAIN_FOLDER = r'C:\\Users\\wiqwe\\Desktop\\上交科研\\selected_positive_#1_imgs_train'\n",
    "POSITIVE_1_IMGS_VALIDATION_FOLDER = r'C:\\Users\\wiqwe\\Desktop\\上交科研\\selected_positive_#1_imgs_validation'\n",
    "POSITIVE_2_IMGS_FOLDER = r'C:\\Users\\wiqwe\\Desktop\\上交科研\\selected_positive_#2_imgs'\n",
    "POSITIVE_2_IMGS_TRAIN_FOLDER = r'C:\\Users\\wiqwe\\Desktop\\上交科研\\selected_positive_#2_imgs_train'\n",
    "POSITIVE_2_IMGS_VALIDATION_FOLDER = r'C:\\Users\\wiqwe\\Desktop\\上交科研\\selected_positive_#2_imgs_validation'\n",
    "NEGATIVE_IMGS_FOLDER = r'C:\\Users\\wiqwe\\Desktop\\上交科研\\selected_negative_imgs'\n",
    "NEGATIVE_IMGS_TRAIN_FOLDER = r'C:\\Users\\wiqwe\\Desktop\\上交科研\\selected_negative_imgs_train'\n",
    "NEGATIVE_IMGS_VALIDATION_FOLDER = r'C:\\Users\\wiqwe\\Desktop\\上交科研\\selected_negative_imgs_validation'\n",
    "\n",
    "train_data = []\n",
    "train_label = []\n",
    "validation_data = []\n",
    "validation_label = []\n",
    "\n",
    "folder_collections = [POSITIVE_1_IMGS_TRAIN_FOLDER, \\\n",
    "                       POSITIVE_1_IMGS_VALIDATION_FOLDER, \\\n",
    "#                        POSITIVE_2_IMGS_TRAIN_FOLDER,\n",
    "#                        POSITIVE_2_IMGS_VALIDATION_FOLDER, \\\n",
    "                       NEGATIVE_IMGS_TRAIN_FOLDER, \\\n",
    "                       NEGATIVE_IMGS_VALIDATION_FOLDER]\n",
    "# Two classes\n",
    "label_collections = [[0, 1], [0, 1],\\\n",
    "                     [1, 0], [1, 0]]\n",
    "\n",
    "# # three classes\n",
    "# label_collections = [[0, 1, 0], [0, 1, 0],\\\n",
    "#                      [0, 0, 1], [0, 0, 1], \\\n",
    "#                      [1, 0, 0], [1, 0, 0]]\n",
    "    \n",
    "for folder_index, current_folder in enumerate(folder_collections):\n",
    "    for img in glob.glob(os.path.join(current_folder ,'*')):\n",
    "        im = PIL.Image.open(img)\n",
    "        # im = im.convert('LA')\n",
    "        im = im.resize((224,224))\n",
    "        im = np.array(im)\n",
    "        im = (im / 255.0) - 1.0\n",
    "    #     im_roll = np.rollaxis(im, 2, 0)\n",
    "    #     assert (im[:,:,0] == im_roll[0,:,:]).all()\n",
    "    #     assert (im[:,:,1] == im_roll[1,:,:]).all()\n",
    "    #     assert (im[:,:,2] == im_roll[2,:,:]).all()\n",
    "        if 'train' in current_folder:\n",
    "            train_data.append(np.array(im))\n",
    "            train_label.append(label_collections[folder_index])\n",
    "        elif 'validation' in current_folder:\n",
    "            validation_data.append(np.array(im))\n",
    "            validation_label.append(label_collections[folder_index])\n",
    "        else:\n",
    "            print(current_folder)\n",
    "            raise TypeError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2137 (224, 224, 3) 2137\n",
      "376 (224, 224, 3) 376\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data), train_data[0].shape, len(train_label))\n",
    "print(len(validation_data), validation_data[0].shape, len(validation_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recovered_img = ((train_data[0]+1)*255).astype(np.uint8)\n",
    "print(recovered_img.shape)\n",
    "PIL.Image.fromarray(recovered_img).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2137, 224, 224, 3) (2137, 2) (376, 224, 224, 3) (376, 2)\n"
     ]
    }
   ],
   "source": [
    "# stack the train and validation list to array\n",
    "train_data = np.stack(train_data, axis=0)\n",
    "train_label = np.array(train_label)\n",
    "validation_data = np.stack(validation_data, axis=0)\n",
    "validation_label = np.array(validation_label)\n",
    "print(train_data.shape, train_label.shape, validation_data.shape, validation_label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Resnet 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resnet_50 = ResnetBuilder.build_resnet_50((3,224,224), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.Adam(lr=0.001, amsgrad=True, decay=0.00005)\n",
    "resnet_50.compile(optimizer, loss=keras.losses.categorical_crossentropy, metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callback function to save model every 10 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate schedular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter searching for resnet 50, train for 100 epoch\n",
    "# lr -> {0.001, 0.005, 0.0005}\n",
    "# decay -> {0.00005, 0.0001, 0.0005}\n",
    "# l2 - > {1e-3}\n",
    "# sample weight if train on two classes -> {None}\n",
    "\n",
    "# 0.001, 0.00005, 1e-3, None -> two classes 0.23 96%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 2137 samples, validate on 376 samples\n",
      "Epoch 1/50\n",
      "2137/2137 [==============================] - 212s 99ms/step - loss: 30.0845 - categorical_accuracy: 0.8723 - val_loss: 22.2446 - val_categorical_accuracy: 0.1702\n",
      "Epoch 2/50\n",
      "2137/2137 [==============================] - 30s 14ms/step - loss: 9.2205 - categorical_accuracy: 0.9134 - val_loss: 5.9337 - val_categorical_accuracy: 0.8404\n",
      "Epoch 3/50\n",
      "2137/2137 [==============================] - 30s 14ms/step - loss: 4.1844 - categorical_accuracy: 0.9270 - val_loss: 3.2926 - val_categorical_accuracy: 0.8457\n",
      "Epoch 4/50\n",
      "2137/2137 [==============================] - 29s 14ms/step - loss: 2.5205 - categorical_accuracy: 0.9448 - val_loss: 2.7488 - val_categorical_accuracy: 0.6782\n",
      "Epoch 5/50\n",
      "2137/2137 [==============================] - 30s 14ms/step - loss: 1.7908 - categorical_accuracy: 0.9565 - val_loss: 2.0499 - val_categorical_accuracy: 0.7048\n",
      "Epoch 6/50\n",
      "2137/2137 [==============================] - 29s 14ms/step - loss: 1.4387 - categorical_accuracy: 0.9598 - val_loss: 2.1904 - val_categorical_accuracy: 0.8298\n",
      "Epoch 7/50\n",
      "2137/2137 [==============================] - 29s 14ms/step - loss: 1.1915 - categorical_accuracy: 0.9640 - val_loss: 1.5437 - val_categorical_accuracy: 0.8431\n",
      "Epoch 8/50\n",
      "2137/2137 [==============================] - 29s 14ms/step - loss: 1.0639 - categorical_accuracy: 0.9668 - val_loss: 1.4157 - val_categorical_accuracy: 0.8324\n",
      "Epoch 9/50\n",
      "2137/2137 [==============================] - 29s 14ms/step - loss: 0.8952 - categorical_accuracy: 0.9715 - val_loss: 2.6251 - val_categorical_accuracy: 0.1702\n",
      "Epoch 10/50\n",
      "2137/2137 [==============================] - 29s 14ms/step - loss: 0.8502 - categorical_accuracy: 0.9691 - val_loss: 1.2555 - val_categorical_accuracy: 0.8404\n",
      "Epoch 11/50\n",
      "2137/2137 [==============================] - 29s 14ms/step - loss: 0.7840 - categorical_accuracy: 0.9743 - val_loss: 1.8701 - val_categorical_accuracy: 0.4894\n",
      "Epoch 12/50\n",
      "2137/2137 [==============================] - 30s 14ms/step - loss: 0.6760 - categorical_accuracy: 0.9813 - val_loss: 1.6979 - val_categorical_accuracy: 0.2872\n",
      "Epoch 13/50\n",
      "2137/2137 [==============================] - 29s 14ms/step - loss: 0.6000 - categorical_accuracy: 0.9818 - val_loss: 2.8114 - val_categorical_accuracy: 0.1888\n",
      "Epoch 14/50\n",
      "2137/2137 [==============================] - 29s 14ms/step - loss: 0.5916 - categorical_accuracy: 0.9813 - val_loss: 2.4199 - val_categorical_accuracy: 0.1782\n",
      "Epoch 15/50\n",
      "2137/2137 [==============================] - 31s 14ms/step - loss: 0.6369 - categorical_accuracy: 0.9883 - val_loss: 1.0391 - val_categorical_accuracy: 0.8644\n",
      "Epoch 16/50\n",
      "2137/2137 [==============================] - 30s 14ms/step - loss: 0.5570 - categorical_accuracy: 0.9803 - val_loss: 0.6981 - val_categorical_accuracy: 0.9069\n",
      "Epoch 17/50\n",
      "2137/2137 [==============================] - 30s 14ms/step - loss: 0.4786 - categorical_accuracy: 0.9832 - val_loss: 0.7497 - val_categorical_accuracy: 0.8856\n",
      "Epoch 18/50\n",
      "2137/2137 [==============================] - 30s 14ms/step - loss: 0.4479 - categorical_accuracy: 0.9846 - val_loss: 1.6314 - val_categorical_accuracy: 0.2606\n",
      "Epoch 19/50\n",
      "2137/2137 [==============================] - 30s 14ms/step - loss: 0.4819 - categorical_accuracy: 0.9897 - val_loss: 0.6360 - val_categorical_accuracy: 0.9388\n",
      "Epoch 20/50\n",
      "2137/2137 [==============================] - 30s 14ms/step - loss: 0.3875 - categorical_accuracy: 0.9888 - val_loss: 1.2118 - val_categorical_accuracy: 0.4495\n",
      "Epoch 21/50\n",
      "2137/2137 [==============================] - 30s 14ms/step - loss: 0.4032 - categorical_accuracy: 0.9789 - val_loss: 0.6456 - val_categorical_accuracy: 0.9016\n",
      "Epoch 22/50\n",
      "2137/2137 [==============================] - 30s 14ms/step - loss: 0.3606 - categorical_accuracy: 0.9897 - val_loss: 2.9479 - val_categorical_accuracy: 0.1702\n",
      "Epoch 23/50\n",
      "2137/2137 [==============================] - 30s 14ms/step - loss: 0.3145 - categorical_accuracy: 0.9944 - val_loss: 1.8951 - val_categorical_accuracy: 0.1968\n",
      "Epoch 24/50\n",
      "2137/2137 [==============================] - 30s 14ms/step - loss: 0.4260 - categorical_accuracy: 0.9841 - val_loss: 0.5634 - val_categorical_accuracy: 0.9229\n",
      "Epoch 25/50\n",
      "2137/2137 [==============================] - 30s 14ms/step - loss: 0.3234 - categorical_accuracy: 0.9878 - val_loss: 1.1174 - val_categorical_accuracy: 0.4628\n",
      "Epoch 26/50\n",
      "2137/2137 [==============================] - 29s 14ms/step - loss: 0.3037 - categorical_accuracy: 0.9906 - val_loss: 1.0597 - val_categorical_accuracy: 0.4309\n",
      "Epoch 27/50\n",
      "2137/2137 [==============================] - 30s 14ms/step - loss: 0.2954 - categorical_accuracy: 0.9892 - val_loss: 0.4371 - val_categorical_accuracy: 0.9335\n",
      "Epoch 28/50\n",
      "2137/2137 [==============================] - 29s 14ms/step - loss: 0.2988 - categorical_accuracy: 0.9869 - val_loss: 1.6661 - val_categorical_accuracy: 0.4495\n",
      "Epoch 29/50\n",
      "2137/2137 [==============================] - 30s 14ms/step - loss: 0.2832 - categorical_accuracy: 0.9902 - val_loss: 0.6405 - val_categorical_accuracy: 0.8032\n",
      "Epoch 30/50\n",
      "2137/2137 [==============================] - 30s 14ms/step - loss: 0.2324 - categorical_accuracy: 0.9939 - val_loss: 2.9170 - val_categorical_accuracy: 0.1702\n",
      "Epoch 31/50\n",
      "2137/2137 [==============================] - 30s 14ms/step - loss: 1.0443 - categorical_accuracy: 0.9448 - val_loss: 5.8587 - val_categorical_accuracy: 0.5798\n",
      "Epoch 32/50\n",
      "2137/2137 [==============================] - 30s 14ms/step - loss: 0.5642 - categorical_accuracy: 0.9719 - val_loss: 0.8580 - val_categorical_accuracy: 0.7473\n",
      "Epoch 33/50\n",
      "2137/2137 [==============================] - 30s 14ms/step - loss: 0.3355 - categorical_accuracy: 0.9855 - val_loss: 1.1618 - val_categorical_accuracy: 0.1968\n",
      "Epoch 34/50\n",
      "2137/2137 [==============================] - 30s 14ms/step - loss: 0.3007 - categorical_accuracy: 0.9883 - val_loss: 0.5474 - val_categorical_accuracy: 0.8431\n",
      "Epoch 35/50\n",
      "2137/2137 [==============================] - 30s 14ms/step - loss: 0.2827 - categorical_accuracy: 0.9878 - val_loss: 1.4846 - val_categorical_accuracy: 0.1729\n",
      "Epoch 36/50\n",
      "2137/2137 [==============================] - 29s 14ms/step - loss: 0.2874 - categorical_accuracy: 0.9920 - val_loss: 0.7673 - val_categorical_accuracy: 0.7128\n",
      "Epoch 37/50\n",
      "2137/2137 [==============================] - 30s 14ms/step - loss: 0.2584 - categorical_accuracy: 0.9878 - val_loss: 1.0792 - val_categorical_accuracy: 0.4255\n",
      "Epoch 38/50\n",
      "2137/2137 [==============================] - 29s 14ms/step - loss: 0.2811 - categorical_accuracy: 0.9902 - val_loss: 2.9176 - val_categorical_accuracy: 0.1702\n",
      "Epoch 39/50\n",
      "2137/2137 [==============================] - 30s 14ms/step - loss: 0.2005 - categorical_accuracy: 0.9977 - val_loss: 1.7771 - val_categorical_accuracy: 0.1702\n",
      "Epoch 40/50\n",
      "2137/2137 [==============================] - 29s 14ms/step - loss: 0.1910 - categorical_accuracy: 0.9991 - val_loss: 2.6353 - val_categorical_accuracy: 0.1702\n",
      "Epoch 41/50\n",
      "2137/2137 [==============================] - 29s 14ms/step - loss: 0.2404 - categorical_accuracy: 0.9911 - val_loss: 3.1600 - val_categorical_accuracy: 0.8298\n",
      "Epoch 42/50\n",
      "2137/2137 [==============================] - 30s 14ms/step - loss: 0.5229 - categorical_accuracy: 0.9850 - val_loss: 0.5471 - val_categorical_accuracy: 0.9043\n",
      "Epoch 43/50\n",
      "2137/2137 [==============================] - 30s 14ms/step - loss: 0.2217 - categorical_accuracy: 0.9972 - val_loss: 1.1685 - val_categorical_accuracy: 0.3245\n",
      "Epoch 44/50\n",
      "2137/2137 [==============================] - 30s 14ms/step - loss: 0.2175 - categorical_accuracy: 0.9958 - val_loss: 1.6891 - val_categorical_accuracy: 0.1702\n",
      "Epoch 45/50\n",
      "2137/2137 [==============================] - 30s 14ms/step - loss: 0.2212 - categorical_accuracy: 0.9934 - val_loss: 2.5199 - val_categorical_accuracy: 0.1702\n",
      "Epoch 46/50\n",
      "2137/2137 [==============================] - 30s 14ms/step - loss: 0.1813 - categorical_accuracy: 0.9977 - val_loss: 2.2997 - val_categorical_accuracy: 0.1702\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50\n",
      "2137/2137 [==============================] - 30s 14ms/step - loss: 0.1845 - categorical_accuracy: 0.9958 - val_loss: 1.9337 - val_categorical_accuracy: 0.2287\n",
      "Epoch 48/50\n",
      "2137/2137 [==============================] - 30s 14ms/step - loss: 0.1800 - categorical_accuracy: 0.9963 - val_loss: 0.7755 - val_categorical_accuracy: 0.7633\n",
      "Epoch 49/50\n",
      "2137/2137 [==============================] - 30s 14ms/step - loss: 0.2178 - categorical_accuracy: 0.9878 - val_loss: 1.0442 - val_categorical_accuracy: 0.9016\n",
      "Epoch 50/50\n",
      "2137/2137 [==============================] - 29s 14ms/step - loss: 0.2060 - categorical_accuracy: 0.9892 - val_loss: 0.5163 - val_categorical_accuracy: 0.8378\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1889854fac8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet_50.fit(train_data, train_label, epochs=50, batch_size=32, validation_data=(validation_data, validation_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2137 samples, validate on 376 samples\n",
      "Epoch 1/50\n",
      "2137/2137 [==============================] - 412s 193ms/step - loss: 0.1487 - categorical_accuracy: 0.9986 - val_loss: 2.4327 - val_categorical_accuracy: 0.1702\n",
      "Epoch 2/50\n",
      "2137/2137 [==============================] - 29s 14ms/step - loss: 0.1322 - categorical_accuracy: 0.9995 - val_loss: 3.0938 - val_categorical_accuracy: 0.1702\n",
      "Epoch 3/50\n",
      "2137/2137 [==============================] - 29s 14ms/step - loss: 0.1228 - categorical_accuracy: 1.0000 - val_loss: 3.2066 - val_categorical_accuracy: 0.1702\n",
      "Epoch 4/50\n",
      "2137/2137 [==============================] - 29s 14ms/step - loss: 0.1175 - categorical_accuracy: 1.0000 - val_loss: 2.8415 - val_categorical_accuracy: 0.1702\n",
      "Epoch 5/50\n",
      "2137/2137 [==============================] - 29s 14ms/step - loss: 0.1117 - categorical_accuracy: 1.0000 - val_loss: 2.6338 - val_categorical_accuracy: 0.1702\n",
      "Epoch 6/50\n",
      "2137/2137 [==============================] - 29s 14ms/step - loss: 0.1066 - categorical_accuracy: 1.0000 - val_loss: 2.3874 - val_categorical_accuracy: 0.1702\n",
      "Epoch 7/50\n",
      "2137/2137 [==============================] - 29s 14ms/step - loss: 0.1028 - categorical_accuracy: 1.0000 - val_loss: 2.1322 - val_categorical_accuracy: 0.1702\n",
      "Epoch 8/50\n",
      "2137/2137 [==============================] - 29s 14ms/step - loss: 0.1324 - categorical_accuracy: 0.9963 - val_loss: 1.7132 - val_categorical_accuracy: 0.8723\n",
      "Epoch 9/50\n",
      "2137/2137 [==============================] - 30s 14ms/step - loss: 0.1303 - categorical_accuracy: 0.9981 - val_loss: 0.5488 - val_categorical_accuracy: 0.8431\n",
      "Epoch 10/50\n",
      "2137/2137 [==============================] - 29s 14ms/step - loss: 0.1123 - categorical_accuracy: 1.0000 - val_loss: 0.7066 - val_categorical_accuracy: 0.7394\n",
      "Epoch 11/50\n",
      "2137/2137 [==============================] - 29s 14ms/step - loss: 0.1057 - categorical_accuracy: 1.0000 - val_loss: 0.7988 - val_categorical_accuracy: 0.6809\n",
      "Epoch 12/50\n",
      "2137/2137 [==============================] - 29s 14ms/step - loss: 0.1021 - categorical_accuracy: 1.0000 - val_loss: 0.7512 - val_categorical_accuracy: 0.7128\n",
      "Epoch 13/50\n",
      "2137/2137 [==============================] - 29s 14ms/step - loss: 0.0995 - categorical_accuracy: 1.0000 - val_loss: 0.6597 - val_categorical_accuracy: 0.7660\n",
      "Epoch 14/50\n",
      "2137/2137 [==============================] - 29s 14ms/step - loss: 0.0974 - categorical_accuracy: 1.0000 - val_loss: 0.6324 - val_categorical_accuracy: 0.7899\n",
      "Epoch 15/50\n",
      "2137/2137 [==============================] - 29s 14ms/step - loss: 0.0957 - categorical_accuracy: 1.0000 - val_loss: 0.6020 - val_categorical_accuracy: 0.7952\n",
      "Epoch 16/50\n",
      "2137/2137 [==============================] - 29s 14ms/step - loss: 0.0943 - categorical_accuracy: 1.0000 - val_loss: 0.5913 - val_categorical_accuracy: 0.8138\n",
      "Epoch 17/50\n",
      "2137/2137 [==============================] - 29s 14ms/step - loss: 0.0929 - categorical_accuracy: 1.0000 - val_loss: 0.5202 - val_categorical_accuracy: 0.8590\n",
      "Epoch 18/50\n",
      "2137/2137 [==============================] - 29s 14ms/step - loss: 0.0916 - categorical_accuracy: 1.0000 - val_loss: 0.5065 - val_categorical_accuracy: 0.8670\n",
      "Epoch 19/50\n",
      "2137/2137 [==============================] - 29s 14ms/step - loss: 0.0905 - categorical_accuracy: 1.0000 - val_loss: 0.4786 - val_categorical_accuracy: 0.8856\n",
      "Epoch 20/50\n",
      "2137/2137 [==============================] - 29s 14ms/step - loss: 0.0893 - categorical_accuracy: 1.0000 - val_loss: 0.5243 - val_categorical_accuracy: 0.8617\n",
      "Epoch 21/50\n",
      "2137/2137 [==============================] - 30s 14ms/step - loss: 0.0882 - categorical_accuracy: 1.0000 - val_loss: 0.5489 - val_categorical_accuracy: 0.8564\n",
      "Epoch 22/50\n",
      "2137/2137 [==============================] - 29s 14ms/step - loss: 0.0872 - categorical_accuracy: 1.0000 - val_loss: 0.6051 - val_categorical_accuracy: 0.8431\n",
      "Epoch 23/50\n",
      "2137/2137 [==============================] - 29s 14ms/step - loss: 0.0862 - categorical_accuracy: 1.0000 - val_loss: 0.6140 - val_categorical_accuracy: 0.8511\n",
      "Epoch 24/50\n",
      "2137/2137 [==============================] - 29s 14ms/step - loss: 0.0852 - categorical_accuracy: 1.0000 - val_loss: 0.6742 - val_categorical_accuracy: 0.8298\n",
      "Epoch 25/50\n",
      "2137/2137 [==============================] - 30s 14ms/step - loss: 0.0844 - categorical_accuracy: 1.0000 - val_loss: 0.4538 - val_categorical_accuracy: 0.9149\n",
      "Epoch 26/50\n",
      "2137/2137 [==============================] - 29s 14ms/step - loss: 0.0835 - categorical_accuracy: 1.0000 - val_loss: 0.3706 - val_categorical_accuracy: 0.9282\n",
      "Epoch 27/50\n",
      "2137/2137 [==============================] - 29s 14ms/step - loss: 0.0827 - categorical_accuracy: 1.0000 - val_loss: 0.7080 - val_categorical_accuracy: 0.7952\n",
      "Epoch 28/50\n",
      "2137/2137 [==============================] - 29s 14ms/step - loss: 0.0819 - categorical_accuracy: 1.0000 - val_loss: 0.4540 - val_categorical_accuracy: 0.9149\n",
      "Epoch 29/50\n",
      "2137/2137 [==============================] - 29s 14ms/step - loss: 0.0810 - categorical_accuracy: 1.0000 - val_loss: 0.9781 - val_categorical_accuracy: 0.7420\n",
      "Epoch 30/50\n",
      "2137/2137 [==============================] - 29s 14ms/step - loss: 0.0803 - categorical_accuracy: 1.0000 - val_loss: 0.3826 - val_categorical_accuracy: 0.9229\n",
      "Epoch 31/50\n",
      "2137/2137 [==============================] - 29s 14ms/step - loss: 0.0796 - categorical_accuracy: 1.0000 - val_loss: 0.3645 - val_categorical_accuracy: 0.9388\n",
      "Epoch 32/50\n",
      "2137/2137 [==============================] - 29s 14ms/step - loss: 0.0789 - categorical_accuracy: 1.0000 - val_loss: 1.3171 - val_categorical_accuracy: 0.6543\n",
      "Epoch 33/50\n",
      "2137/2137 [==============================] - 29s 14ms/step - loss: 0.0782 - categorical_accuracy: 1.0000 - val_loss: 0.7685 - val_categorical_accuracy: 0.8404\n",
      "Epoch 34/50\n",
      "2137/2137 [==============================] - 29s 14ms/step - loss: 0.0774 - categorical_accuracy: 1.0000 - val_loss: 0.3415 - val_categorical_accuracy: 0.9309\n",
      "Epoch 35/50\n",
      "2137/2137 [==============================] - 29s 14ms/step - loss: 0.0768 - categorical_accuracy: 1.0000 - val_loss: 0.8090 - val_categorical_accuracy: 0.8085\n",
      "Epoch 36/50\n",
      "2137/2137 [==============================] - 29s 14ms/step - loss: 0.0761 - categorical_accuracy: 1.0000 - val_loss: 0.6268 - val_categorical_accuracy: 0.8431\n",
      "Epoch 37/50\n",
      "2137/2137 [==============================] - 29s 14ms/step - loss: 0.0755 - categorical_accuracy: 1.0000 - val_loss: 0.6496 - val_categorical_accuracy: 0.8963\n",
      "Epoch 38/50\n",
      "2137/2137 [==============================] - 30s 14ms/step - loss: 0.0753 - categorical_accuracy: 1.0000 - val_loss: 0.8661 - val_categorical_accuracy: 0.8936\n",
      "Epoch 39/50\n",
      "2137/2137 [==============================] - 29s 14ms/step - loss: 0.0744 - categorical_accuracy: 1.0000 - val_loss: 0.7919 - val_categorical_accuracy: 0.7713\n",
      "Epoch 40/50\n",
      "2137/2137 [==============================] - 29s 14ms/step - loss: 0.0741 - categorical_accuracy: 1.0000 - val_loss: 2.8195 - val_categorical_accuracy: 0.8298\n",
      "Epoch 41/50\n",
      "2137/2137 [==============================] - 29s 14ms/step - loss: 0.0768 - categorical_accuracy: 1.0000 - val_loss: 0.4235 - val_categorical_accuracy: 0.9628\n",
      "Epoch 42/50\n",
      "2137/2137 [==============================] - 30s 14ms/step - loss: 0.0740 - categorical_accuracy: 1.0000 - val_loss: 0.5880 - val_categorical_accuracy: 0.8351\n",
      "Epoch 43/50\n",
      "2137/2137 [==============================] - 30s 14ms/step - loss: 0.0726 - categorical_accuracy: 1.0000 - val_loss: 0.8294 - val_categorical_accuracy: 0.7261\n",
      "Epoch 44/50\n",
      "2137/2137 [==============================] - 29s 14ms/step - loss: 0.0717 - categorical_accuracy: 1.0000 - val_loss: 0.8518 - val_categorical_accuracy: 0.7234\n",
      "Epoch 45/50\n",
      "2137/2137 [==============================] - 30s 14ms/step - loss: 0.0711 - categorical_accuracy: 1.0000 - val_loss: 0.8018 - val_categorical_accuracy: 0.7287\n",
      "Epoch 46/50\n",
      "2137/2137 [==============================] - 29s 14ms/step - loss: 0.0704 - categorical_accuracy: 1.0000 - val_loss: 0.8550 - val_categorical_accuracy: 0.7207\n",
      "Epoch 47/50\n",
      "2137/2137 [==============================] - 30s 14ms/step - loss: 0.0701 - categorical_accuracy: 1.0000 - val_loss: 2.7725 - val_categorical_accuracy: 0.8298\n",
      "Epoch 48/50\n",
      "2137/2137 [==============================] - 30s 14ms/step - loss: 0.1917 - categorical_accuracy: 0.9832 - val_loss: 2.8722 - val_categorical_accuracy: 0.8298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50\n",
      "2137/2137 [==============================] - 30s 14ms/step - loss: 0.1234 - categorical_accuracy: 1.0000 - val_loss: 0.2402 - val_categorical_accuracy: 0.9681\n",
      "Epoch 50/50\n",
      "2137/2137 [==============================] - 29s 14ms/step - loss: 0.1113 - categorical_accuracy: 1.0000 - val_loss: 0.2316 - val_categorical_accuracy: 0.9601\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18898447c88>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weak_optimizer = keras.optimizers.Adam(lr=0.0001, amsgrad=True, decay=0.00005)\n",
    "resnet_50.compile(weak_optimizer, loss=keras.losses.categorical_crossentropy, metrics=['categorical_accuracy'])\n",
    "resnet_50.fit(train_data, train_label, epochs=50, batch_size=32, validation_data=(validation_data, validation_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:507: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with distribution=normal is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`normal` is a deprecated alias for `truncated_normal`\n"
     ]
    }
   ],
   "source": [
    "#model io\n",
    "import tensorflow as tf\n",
    "# resnet_50.save('50ep_001_50ep_0001_0.00005.h5')\n",
    "resnet_50 = tf.keras.models.load_model('50ep_001_50ep_0001_0.00005.h5', custom_objects=None, compile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 15\n"
     ]
    }
   ],
   "source": [
    "# Show wrong samples and find threshold\n",
    "prediction = resnet_50.predict(validation_data)\n",
    "# prediction_threshold = 0.5\n",
    "for prediction_threshold in [0.5]:\n",
    "    prediction_result = prediction > prediction_threshold\n",
    "    wrongly_predicted_image = []\n",
    "    wrongly_predicted_image_correct_label = []\n",
    "    wrongly_predicted_image_PS = []\n",
    "    for i in range(prediction.shape[0]):\n",
    "        if prediction_result[i,1] != validation_label[i,1]:\n",
    "            wrongly_predicted_image.append(validation_data[i])\n",
    "            wrongly_predicted_image_correct_label.append(validation_label[i])\n",
    "            wrongly_predicted_image_PS.append(prediction[i,:])\n",
    "    print(prediction_threshold, len(wrongly_predicted_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "import seaborn as sn\n",
    "import numpy as np\n",
    "\n",
    "def draw_confusion_matrix(tn, fp, fn, tp):\n",
    "    cm_df = pd.DataFrame(np.array([[tp, fn], [fp, tn]]), ['Real_Pos', 'Real_Neg'], \\\n",
    "                                                         ['Predicted_Pos', 'Predicted_Neg'])\n",
    "    sn.set(font_scale=1.4)\n",
    "    sn.heatmap(cm_df, annot=True)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "for prediction_threshold in [0.5]:\n",
    "    prediction_result = prediction > prediction_threshold\n",
    "    prediction_col = prediction_result[:,1]\n",
    "    validation_label_col = validation_label[:,1]\n",
    "    tn, fp, fn, tp = confusion_matrix(validation_label_col, prediction_col).ravel()\n",
    "    draw_confusion_matrix(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sensitivity specificity accuracy\n",
    "def get_specificity(tn, fp):\n",
    "    return tn / (tn+fp)\n",
    "\n",
    "def get_sensitivity(tp, fn):\n",
    "    return tp / (tp+fn)\n",
    "\n",
    "def get_accuracy(tp,tn,fp,fn):\n",
    "    return (tp+tn) / (tp+tn+fn+fp)\n",
    "\n",
    "thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "specificity, sensitivity, accuracy = [], [], [] \n",
    "from sklearn.metrics import confusion_matrix\n",
    "for prediction_threshold in thresholds:\n",
    "    prediction_result = prediction > prediction_threshold\n",
    "    prediction_col = prediction_result[:,1]\n",
    "    validation_label_col = validation_label[:,1]\n",
    "    tn, fp, fn, tp = confusion_matrix(validation_label_col, prediction_col).ravel()\n",
    "    specificity.append(get_specificity(tn, fp))\n",
    "    sensitivity.append(get_sensitivity(tp, fn))\n",
    "    accuracy.append(get_accuracy(tp,tn,fp,fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cnn thresholds</th>\n",
       "      <th>specificity</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.935897</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.946809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.945513</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.954787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.957447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.951923</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.960106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.955128</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>0.960106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>0.962766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.953125</td>\n",
       "      <td>0.960106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.964744</td>\n",
       "      <td>0.953125</td>\n",
       "      <td>0.962766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.964744</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.960106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cnn thresholds  specificity  sensitivity  accuracy\n",
       "0             0.1     0.935897     1.000000  0.946809\n",
       "1             0.2     0.945513     1.000000  0.954787\n",
       "2             0.3     0.948718     1.000000  0.957447\n",
       "3             0.4     0.951923     1.000000  0.960106\n",
       "4             0.5     0.955128     0.984375  0.960106\n",
       "5             0.6     0.958333     0.984375  0.962766\n",
       "6             0.7     0.961538     0.953125  0.960106\n",
       "7             0.8     0.964744     0.953125  0.962766\n",
       "8             0.9     0.964744     0.937500  0.960106"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = {'cnn thresholds':thresholds, 'specificity':specificity, 'sensitivity':sensitivity, 'accuracy':accuracy}\n",
    "pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.590522825717926, 0.40947723388671875], [0.003439075779169798, 0.9965608716011047], [0.04511618986725807, 0.9548837542533875], [0.09575380384922028, 0.9042462110519409], [0.005804746877402067, 0.994195282459259], [0.04147651046514511, 0.9585234522819519], [0.08794502168893814, 0.9120549559593201], [0.38487687706947327, 0.6151231527328491], [0.015596226789057255, 0.9844038486480713], [0.2486422210931778, 0.7513577938079834], [0.06163264811038971, 0.9383673071861267], [0.4147565960884094, 0.5852433443069458], [0.029385380446910858, 0.9706146717071533], [0.04999309405684471, 0.9500069618225098], [0.02438129112124443, 0.9756187200546265]]\n"
     ]
    }
   ],
   "source": [
    "print(list(map(lambda x: x.tolist(), wrongly_predicted_image_PS)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save misclassified images\n",
    "for index in range(len(wrongly_predicted_image)):\n",
    "    recovered_img = ((wrongly_predicted_image[index]+1)*255).astype(np.uint8)\n",
    "    PIL.Image.fromarray(recovered_img).save(r'C:\\Users\\wiqwe\\Desktop\\上交科研\\misclassfied_images\\{}.jpg'.format(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zip files\n",
    "import os\n",
    "import zipfile\n",
    " \n",
    "zip_object = zipfile.ZipFile(r'C:\\Users\\wiqwe\\Desktop\\上交科研\\misclassfied_images.zip', 'w')\n",
    " \n",
    "for folder, subfolders, files in os.walk(r'C:\\Users\\wiqwe\\Desktop\\上交科研\\misclassfied_images'):\n",
    "    for file in files:\n",
    "        zip_object.write(os.path.join(folder, file), os.path.relpath(os.path.join(folder,file), r'C:\\Users\\wiqwe\\Desktop\\上交科研\\misclassfied_images'), compress_type = zipfile.ZIP_DEFLATED)\n",
    " \n",
    "zip_object.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(wrongly_predicted_image)\n",
    "def show_image(img):\n",
    "    recovered_img = ((img+1)*255).astype(np.uint8)\n",
    "    PIL.Image.fromarray(recovered_img).show()\n",
    "\n",
    "# for i in range(len(wrongly_predicted_image)):\n",
    "#     show_image(wrongly_predicted_image[i])\n",
    "#     print(wrongly_predicted_image_correct_label[i])\n",
    "\n",
    "big_image = np.zeros((224, 224 * len(wrongly_predicted_image), 3))\n",
    "for i in range(len(wrongly_predicted_image)):\n",
    "    big_image[:,224*i:224*(i+1),:] = wrongly_predicted_image[i]\n",
    "show_image(big_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prediction_result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-2987eb91ea95>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# ROC curve\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mfpr_keras\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr_keras\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthresholds_keras\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidation_label\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprediction_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'prediction_result' is not defined"
     ]
    }
   ],
   "source": [
    "# ROC curve\n",
    "from sklearn.metrics import roc_curve\n",
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(validation_label.ravel(), prediction_result.ravel())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9601063829787235\n"
     ]
    }
   ],
   "source": [
    "# AUC\n",
    "from sklearn.metrics import auc\n",
    "auc_keras = auc(fpr_keras, tpr_keras)\n",
    "print(auc_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the graph\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_keras, tpr_keras, label='Resnet 50 (area = {:.3f})'.format(auc_keras))\n",
    "# plt.plot(fpr_rf, tpr_rf, label='RF (area = {:.3f})'.format(auc_rf))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate on videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frame the video\n",
    "import cv2\n",
    "\n",
    "def extract_video_frames(video_path):\n",
    "    vidcap = cv2.VideoCapture(video_path)\n",
    "    success, image = vidcap.read()\n",
    "    count = 0\n",
    "    while success:\n",
    "        cv2.imwrite(\"frame%d.jpg\" % count, image)     # save frame as JPEG file      \n",
    "        success,image = vidcap.read()\n",
    "        print('Read a new frame: ', success)\n",
    "        count += 1\n",
    "        \n",
    "VIDEO_DIR = r'C:\\Users\\wiqwe\\Desktop\\上交科研\\selected_positive_#1_imgs'\n",
    "VIDEO_FRAME_DIR = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix -- keras Resnet definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import six\n",
    "\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.layers import (\n",
    "\n",
    "    Input,\n",
    "\n",
    "    Activation,\n",
    "\n",
    "    Dense,\n",
    "\n",
    "    Flatten\n",
    "\n",
    ")\n",
    "\n",
    "from keras.layers.convolutional import (\n",
    "\n",
    "    Conv2D,\n",
    "\n",
    "    MaxPooling2D,\n",
    "\n",
    "    AveragePooling2D\n",
    "\n",
    ")\n",
    "\n",
    "from keras.layers.merge import add\n",
    "\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "from keras.regularizers import l2\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _bn_relu(input):\n",
    "\n",
    "    \"\"\"Helper to build a BN -> relu block\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    norm = BatchNormalization(axis=CHANNEL_AXIS)(input)\n",
    "\n",
    "    return Activation(\"relu\")(norm)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _conv_bn_relu(**conv_params):\n",
    "\n",
    "    \"\"\"Helper to build a conv -> BN -> relu block\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    filters = conv_params[\"filters\"]\n",
    "\n",
    "    kernel_size = conv_params[\"kernel_size\"]\n",
    "\n",
    "    strides = conv_params.setdefault(\"strides\", (1, 1))\n",
    "\n",
    "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
    "\n",
    "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
    "\n",
    "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-3))\n",
    "\n",
    "\n",
    "\n",
    "    def f(input):\n",
    "\n",
    "        conv = Conv2D(filters=filters, kernel_size=kernel_size,\n",
    "\n",
    "                      strides=strides, padding=padding,\n",
    "\n",
    "                      kernel_initializer=kernel_initializer,\n",
    "\n",
    "                      kernel_regularizer=kernel_regularizer)(input)\n",
    "\n",
    "        return _bn_relu(conv)\n",
    "\n",
    "\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _bn_relu_conv(**conv_params):\n",
    "\n",
    "    \"\"\"Helper to build a BN -> relu -> conv block.\n",
    "\n",
    "    This is an improved scheme proposed in http://arxiv.org/pdf/1603.05027v2.pdf\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    filters = conv_params[\"filters\"]\n",
    "\n",
    "    kernel_size = conv_params[\"kernel_size\"]\n",
    "\n",
    "    strides = conv_params.setdefault(\"strides\", (1, 1))\n",
    "\n",
    "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
    "\n",
    "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
    "\n",
    "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-3))\n",
    "\n",
    "\n",
    "\n",
    "    def f(input):\n",
    "\n",
    "        activation = _bn_relu(input)\n",
    "\n",
    "        return Conv2D(filters=filters, kernel_size=kernel_size,\n",
    "\n",
    "                      strides=strides, padding=padding,\n",
    "\n",
    "                      kernel_initializer=kernel_initializer,\n",
    "\n",
    "                      kernel_regularizer=kernel_regularizer)(activation)\n",
    "\n",
    "\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _shortcut(input, residual):\n",
    "\n",
    "    \"\"\"Adds a shortcut between input and residual block and merges them with \"sum\"\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Expand channels of shortcut to match residual.\n",
    "\n",
    "    # Stride appropriately to match residual (width, height)\n",
    "\n",
    "    # Should be int if network architecture is correctly configured.\n",
    "\n",
    "    input_shape = K.int_shape(input)\n",
    "\n",
    "    residual_shape = K.int_shape(residual)\n",
    "\n",
    "    stride_width = int(round(input_shape[ROW_AXIS] / residual_shape[ROW_AXIS]))\n",
    "\n",
    "    stride_height = int(round(input_shape[COL_AXIS] / residual_shape[COL_AXIS]))\n",
    "\n",
    "    equal_channels = input_shape[CHANNEL_AXIS] == residual_shape[CHANNEL_AXIS]\n",
    "\n",
    "\n",
    "\n",
    "    shortcut = input\n",
    "\n",
    "    # 1 X 1 conv if shape is different. Else identity.\n",
    "\n",
    "    if stride_width > 1 or stride_height > 1 or not equal_channels:\n",
    "\n",
    "        shortcut = Conv2D(filters=residual_shape[CHANNEL_AXIS],\n",
    "\n",
    "                          kernel_size=(1, 1),\n",
    "\n",
    "                          strides=(stride_width, stride_height),\n",
    "\n",
    "                          padding=\"valid\",\n",
    "\n",
    "                          kernel_initializer=\"he_normal\",\n",
    "\n",
    "                          kernel_regularizer=l2(0.001))(input)\n",
    "\n",
    "\n",
    "\n",
    "    return add([shortcut, residual])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _residual_block(block_function, filters, repetitions, is_first_layer=False):\n",
    "\n",
    "    \"\"\"Builds a residual block with repeating bottleneck blocks.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def f(input):\n",
    "\n",
    "        for i in range(repetitions):\n",
    "\n",
    "            init_strides = (1, 1)\n",
    "\n",
    "            if i == 0 and not is_first_layer:\n",
    "\n",
    "                init_strides = (2, 2)\n",
    "\n",
    "            input = block_function(filters=filters, init_strides=init_strides,\n",
    "\n",
    "                                   is_first_block_of_first_layer=(is_first_layer and i == 0))(input)\n",
    "\n",
    "        return input\n",
    "\n",
    "\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def basic_block(filters, init_strides=(1, 1), is_first_block_of_first_layer=False):\n",
    "\n",
    "    \"\"\"Basic 3 X 3 convolution blocks for use on resnets with layers <= 34.\n",
    "\n",
    "    Follows improved proposed scheme in http://arxiv.org/pdf/1603.05027v2.pdf\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def f(input):\n",
    "\n",
    "\n",
    "\n",
    "        if is_first_block_of_first_layer:\n",
    "\n",
    "            # don't repeat bn->relu since we just did bn->relu->maxpool\n",
    "\n",
    "            conv1 = Conv2D(filters=filters, kernel_size=(3, 3),\n",
    "\n",
    "                           strides=init_strides,\n",
    "\n",
    "                           padding=\"same\",\n",
    "\n",
    "                           kernel_initializer=\"he_normal\",\n",
    "\n",
    "                           kernel_regularizer=l2(1e-3))(input)\n",
    "\n",
    "        else:\n",
    "\n",
    "            conv1 = _bn_relu_conv(filters=filters, kernel_size=(3, 3),\n",
    "\n",
    "                                  strides=init_strides)(input)\n",
    "\n",
    "\n",
    "\n",
    "        residual = _bn_relu_conv(filters=filters, kernel_size=(3, 3))(conv1)\n",
    "\n",
    "        return _shortcut(input, residual)\n",
    "\n",
    "\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def bottleneck(filters, init_strides=(1, 1), is_first_block_of_first_layer=False):\n",
    "\n",
    "    \"\"\"Bottleneck architecture for > 34 layer resnet.\n",
    "\n",
    "    Follows improved proposed scheme in http://arxiv.org/pdf/1603.05027v2.pdf\n",
    "\n",
    "\n",
    "\n",
    "    Returns:\n",
    "\n",
    "        A final conv layer of filters * 4\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def f(input):\n",
    "\n",
    "\n",
    "\n",
    "        if is_first_block_of_first_layer:\n",
    "\n",
    "            # don't repeat bn->relu since we just did bn->relu->maxpool\n",
    "\n",
    "            conv_1_1 = Conv2D(filters=filters, kernel_size=(1, 1),\n",
    "\n",
    "                              strides=init_strides,\n",
    "\n",
    "                              padding=\"same\",\n",
    "\n",
    "                              kernel_initializer=\"he_normal\",\n",
    "\n",
    "                              kernel_regularizer=l2(1e-3))(input)\n",
    "\n",
    "        else:\n",
    "\n",
    "            conv_1_1 = _bn_relu_conv(filters=filters, kernel_size=(1, 1),\n",
    "\n",
    "                                     strides=init_strides)(input)\n",
    "\n",
    "\n",
    "\n",
    "        conv_3_3 = _bn_relu_conv(filters=filters, kernel_size=(3, 3))(conv_1_1)\n",
    "\n",
    "        residual = _bn_relu_conv(filters=filters * 4, kernel_size=(1, 1))(conv_3_3)\n",
    "\n",
    "        return _shortcut(input, residual)\n",
    "\n",
    "\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _handle_dim_ordering():\n",
    "\n",
    "    global ROW_AXIS\n",
    "\n",
    "    global COL_AXIS\n",
    "\n",
    "    global CHANNEL_AXIS\n",
    "\n",
    "    if K.image_dim_ordering() == 'tf':\n",
    "\n",
    "        ROW_AXIS = 1\n",
    "\n",
    "        COL_AXIS = 2\n",
    "\n",
    "        CHANNEL_AXIS = 3\n",
    "\n",
    "    else:\n",
    "\n",
    "        CHANNEL_AXIS = 1\n",
    "\n",
    "        ROW_AXIS = 2\n",
    "\n",
    "        COL_AXIS = 3\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _get_block(identifier):\n",
    "\n",
    "    if isinstance(identifier, six.string_types):\n",
    "\n",
    "        res = globals().get(identifier)\n",
    "\n",
    "        if not res:\n",
    "\n",
    "            raise ValueError('Invalid {}'.format(identifier))\n",
    "\n",
    "        return res\n",
    "\n",
    "    return identifier\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ResnetBuilder(object):\n",
    "\n",
    "    @staticmethod\n",
    "\n",
    "    def build(input_shape, num_outputs, block_fn, repetitions):\n",
    "\n",
    "        \"\"\"Builds a custom ResNet like architecture.\n",
    "\n",
    "\n",
    "\n",
    "        Args:\n",
    "\n",
    "            input_shape: The input shape in the form (nb_channels, nb_rows, nb_cols)\n",
    "\n",
    "            num_outputs: The number of outputs at final softmax layer\n",
    "\n",
    "            block_fn: The block function to use. This is either `basic_block` or `bottleneck`.\n",
    "\n",
    "                The original paper used basic_block for layers < 50\n",
    "\n",
    "            repetitions: Number of repetitions of various block units.\n",
    "\n",
    "                At each block unit, the number of filters are doubled and the input size is halved\n",
    "\n",
    "\n",
    "\n",
    "        Returns:\n",
    "\n",
    "            The keras `Model`.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        _handle_dim_ordering()\n",
    "\n",
    "        if len(input_shape) != 3:\n",
    "\n",
    "            raise Exception(\"Input shape should be a tuple (nb_channels, nb_rows, nb_cols)\")\n",
    "\n",
    "\n",
    "\n",
    "        # Permute dimension order if necessary\n",
    "\n",
    "        if K.image_dim_ordering() == 'tf':\n",
    "\n",
    "            input_shape = (input_shape[1], input_shape[2], input_shape[0])\n",
    "\n",
    "\n",
    "\n",
    "        # Load function from str if needed.\n",
    "\n",
    "        block_fn = _get_block(block_fn)\n",
    "\n",
    "\n",
    "\n",
    "        input = Input(shape=input_shape)\n",
    "\n",
    "        conv1 = _conv_bn_relu(filters=64, kernel_size=(7, 7), strides=(2, 2))(input)\n",
    "\n",
    "        pool1 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding=\"same\")(conv1)\n",
    "\n",
    "\n",
    "\n",
    "        block = pool1\n",
    "\n",
    "        filters = 64\n",
    "\n",
    "        for i, r in enumerate(repetitions):\n",
    "\n",
    "            block = _residual_block(block_fn, filters=filters, repetitions=r, is_first_layer=(i == 0))(block)\n",
    "\n",
    "            filters *= 2\n",
    "\n",
    "\n",
    "\n",
    "        # Last activation\n",
    "\n",
    "        block = _bn_relu(block)\n",
    "\n",
    "\n",
    "\n",
    "        # Classifier block\n",
    "\n",
    "        block_shape = K.int_shape(block)\n",
    "\n",
    "        pool2 = AveragePooling2D(pool_size=(block_shape[ROW_AXIS], block_shape[COL_AXIS]),\n",
    "\n",
    "                                 strides=(1, 1))(block)\n",
    "\n",
    "        flatten1 = Flatten()(pool2)\n",
    "\n",
    "        dense = Dense(units=num_outputs, kernel_initializer=\"he_normal\",\n",
    "\n",
    "                      activation=\"softmax\")(flatten1)\n",
    "\n",
    "\n",
    "\n",
    "        model = Model(inputs=input, outputs=dense)\n",
    "\n",
    "        return model\n",
    "\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "\n",
    "    def build_resnet_18(input_shape, num_outputs):\n",
    "\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, basic_block, [2, 2, 2, 2])\n",
    "\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "\n",
    "    def build_resnet_34(input_shape, num_outputs):\n",
    "\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, basic_block, [3, 4, 6, 3])\n",
    "\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "\n",
    "    def build_resnet_50(input_shape, num_outputs):\n",
    "\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 4, 6, 3])\n",
    "\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "\n",
    "    def build_resnet_101(input_shape, num_outputs):\n",
    "\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 4, 23, 3])\n",
    "\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "\n",
    "    def build_resnet_152(input_shape, num_outputs):\n",
    "\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 8, 36, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
