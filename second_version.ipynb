{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os, sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter all positive images out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all positive #1 (活动性出血) images -- 429 total images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, glob\n",
    "pos_ind_df = pd.read_excel(r'C:\\Users\\wiqwe\\Desktop\\上交科研\\c活动性出血.xlsx')\n",
    "pos_ind_df.columns\n",
    "name_ind = pos_ind_df[[' 姓名','出血典型病变图片号码']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traverse all positive image folders\n",
    "import re\n",
    "folder_prefix = r'C:\\Users\\wiqwe\\Desktop\\上交科研\\出血'\n",
    "folders = glob.glob(os.path.join(folder_prefix,'*'))\n",
    "# print(folders)\n",
    "name_to_folder = {}\n",
    "\n",
    "def name_extract(folder):\n",
    "    pattern = re.compile('\\d{6,10}(.+)')\n",
    "    name = pattern.findall(folder)\n",
    "    name_to_folder[name[0]] = folder\n",
    "    return name\n",
    "\n",
    "names = [name_extract(i) for i in folders]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy selected images from patient's folder to dataset folder\n",
    "import shutil\n",
    "pos_img_index = 0\n",
    "POSITIVE_IMGS_FOLDER = r'C:\\Users\\wiqwe\\Desktop\\上交科研\\selected_positive_#1_imgs'\n",
    "def func(a):\n",
    "    name, img_inds = a.tolist()\n",
    "    if name.endswith('2'): name = name[:-1]\n",
    "#     print(name, img_inds,'|', type(img_inds), len(img_inds), 'called')\n",
    "    img_inds = img_inds.replace(' ', '').replace('，', ',').strip(',').replace('.',',').split(',')\n",
    "    name = name.strip()\n",
    "#     print(type(img_inds), img_inds)\n",
    "    \n",
    "    def copy_file_func(img_ind):\n",
    "        global pos_img_index\n",
    "        full_path = os.path.join(name_to_folder[name], img_ind + '.jpg')\n",
    "        print(full_path)\n",
    "        paste_path = os.path.join(POSITIVE_IMGS_FOLDER, str(pos_img_index) + '.jpg')\n",
    "        shutil.copyfile(full_path,paste_path)\n",
    "        pos_img_index += 1\n",
    "   \n",
    "    _ = [copy_file_func(i) for i in img_inds]\n",
    "#     print(name, img_inds)\n",
    "    \n",
    "_ = name_ind.apply(func, axis=1, raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all positive #2 (血管畸形) images -- 1169 total images\n",
    "pos_ind_df = pd.read_excel(r'C:\\Users\\wiqwe\\Desktop\\上交科研\\消化道出血病人表-血管畸形80.xlsx', dtype=str)\n",
    "pos_ind_df.columns\n",
    "name_ind = pos_ind_df[[' 姓名','病变图片编号']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "pos_img_index = 429\n",
    "POSITIVE_IMGS_FOLDER = r'C:\\Users\\wiqwe\\Desktop\\上交科研\\selected_positive_#2_imgs'\n",
    "def func(a):\n",
    "    name, img_inds = a.tolist()\n",
    "    if type(img_inds) != str: return\n",
    "    print(name, img_inds, type(img_inds))\n",
    "    img_inds = img_inds.replace(' ', '').replace('，', ',').strip(',').replace('.',',').split(',')\n",
    "    name = name.strip()\n",
    "    print(type(img_inds), img_inds)\n",
    "    \n",
    "    def copy_file_func(img_ind):\n",
    "        global pos_img_index\n",
    "        full_path = os.path.join(name_to_folder[name], img_ind + '.jpg')\n",
    "        print(full_path)\n",
    "        paste_path = os.path.join(POSITIVE_IMGS_FOLDER, str(pos_img_index) + '.jpg')\n",
    "        shutil.copyfile(full_path,paste_path)\n",
    "        pos_img_index += 1\n",
    "   \n",
    "    _ = [copy_file_func(i) for i in img_inds]\n",
    "#     print(name, img_inds)\n",
    "    \n",
    "_ = name_ind.apply(func, axis=1, raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample negative images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get negative images -- 454 * num_per_folder\n",
    "import random\n",
    "import glob, os, shutil\n",
    "NEGATIVE_IMGS_FOLDER = r'C:\\Users\\wiqwe\\Desktop\\上交科研\\selected_negative_imgs'\n",
    "folder_prefix = r'C:\\Users\\wiqwe\\Desktop\\上交科研\\阴性'\n",
    "neg_img_index = 0\n",
    "num_per_folder = 5\n",
    "folders = glob.glob(os.path.join(folder_prefix,'*'))\n",
    "def copy_neg_image(image):\n",
    "    global neg_img_index\n",
    "    image_basename = os.path.basename(image)\n",
    "    paste_path = os.path.join(NEGATIVE_IMGS_FOLDER, str(neg_img_index) + '.jpg')\n",
    "    neg_img_index += 1\n",
    "#     print(image)\n",
    "    shutil.copyfile(image,paste_path)\n",
    "    \n",
    "for folder in folders:\n",
    "    images = glob.glob(os.path.join(folder, '*'))\n",
    "    if not images:\n",
    "        continue\n",
    "    elif len(images) > num_per_folder:\n",
    "        images = random.sample(images, num_per_folder)\n",
    "    for image in images:\n",
    "        copy_neg_image(image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "387 42\n",
      "1055 116\n",
      "1876 208\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\wiqwe\\\\Desktop\\\\上交科研\\\\selected_positive_#1_imgs_train\\\\0.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-fd6005b6d687>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpositive_1_train_indices\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m     \u001b[0mcopy_train_validation_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPOSITIVE_1_IMGS_FOLDER\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPOSITIVE_1_IMGS_TRAIN_FOLDER\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpositive_1_validation_indices\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[0mcopy_train_validation_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPOSITIVE_1_IMGS_FOLDER\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPOSITIVE_1_IMGS_VALIDATION_FOLDER\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-41-fd6005b6d687>\u001b[0m in \u001b[0;36mcopy_train_validation_image\u001b[1;34m(image_index, source_image_folder, des_image_folder)\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[0mpaste_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdes_image_folder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_index\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.jpg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;31m#     print(image)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m     \u001b[0mshutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopyfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpaste_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpositive_1_train_indices\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m             \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfdst\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m                 \u001b[0mcopyfileobj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfsrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfdst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\wiqwe\\\\Desktop\\\\上交科研\\\\selected_positive_#1_imgs_train\\\\0.jpg'"
     ]
    }
   ],
   "source": [
    "# split train and validation set (copy files to different folder)\n",
    "POSITIVE_1_IMGS_FOLDER = r'C:\\Users\\wiqwe\\Desktop\\上交科研\\selected_positive_#1_imgs'\n",
    "POSITIVE_1_IMGS_TRAIN_FOLDER = r'C:\\Users\\wiqwe\\Desktop\\上交科研\\selected_positive_#1_imgs_train'\n",
    "POSITIVE_1_IMGS_VALIDATION_FOLDER = r'C:\\Users\\wiqwe\\Desktop\\上交科研\\selected_positive_#1_imgs_validation'\n",
    "POSITIVE_2_IMGS_FOLDER = r'C:\\Users\\wiqwe\\Desktop\\上交科研\\selected_positive_#2_imgs'\n",
    "POSITIVE_2_IMGS_TRAIN_FOLDER = r'C:\\Users\\wiqwe\\Desktop\\上交科研\\selected_positive_#2_imgs_train'\n",
    "POSITIVE_2_IMGS_VALIDATION_FOLDER = r'C:\\Users\\wiqwe\\Desktop\\上交科研\\selected_positive_#2_imgs_validation'\n",
    "NEGATIVE_IMGS_FOLDER = r'C:\\Users\\wiqwe\\Desktop\\上交科研\\selected_negative_imgs'\n",
    "NEGATIVE_IMGS_TRAIN_FOLDER = r'C:\\Users\\wiqwe\\Desktop\\上交科研\\selected_negative_imgs_train'\n",
    "NEGATIVE_IMGS_VALIDATION_FOLDER = r'C:\\Users\\wiqwe\\Desktop\\上交科研\\selected_negative_imgs_validation'\n",
    "VALIDATION_RATIO = 0.15\n",
    "\n",
    "# split randomly\n",
    "positive_1_imgs = glob.glob(os.path.join(POSITIVE_1_IMGS_FOLDER,'*'))\n",
    "positive_1_validation_indices = random.sample(list(range(429)), int(0.1*429))\n",
    "positive_1_train_indices = list(filter(lambda x: x not in positive_1_validation_indices, list(range(429))))\n",
    "print(len(positive_1_train_indices), len(positive_1_validation_indices))\n",
    "\n",
    "positive_2_imgs = glob.glob(os.path.join(POSITIVE_1_IMGS_FOLDER,'*'))\n",
    "positive_2_validation_indices = random.sample(list(range(429, 1600)), int(0.1*1169))\n",
    "positive_2_train_indices = list(filter(lambda x: x not in positive_2_validation_indices, list(range(429, 1600))))\n",
    "print(len(positive_2_train_indices), len(positive_2_validation_indices))\n",
    "\n",
    "negative_imgs = glob.glob(os.path.join(POSITIVE_1_IMGS_FOLDER,'*'))\n",
    "negative_validation_indices = random.sample(list(range(429)), int(0.1*2084))\n",
    "negative_train_indices = list(filter(lambda x: x not in negative_validation_indices, list(range(2084))))\n",
    "print(len(negative_train_indices), len(negative_validation_indices))\n",
    "\n",
    "#TODO: FIVE FOLD CV\n",
    "\n",
    "# clear folder if already exsits\n",
    "# folder_collections = [POSITIVE_1_IMGS_TRAIN_FOLDER, \\\n",
    "#                        POSITIVE_1_IMGS_VALIDATION_FOLDER, \\\n",
    "#                        POSITIVE_2_IMGS_TRAIN_FOLDER,\n",
    "#                        POSITIVE_2_IMGS_VALIDATION_FOLDER, \\\n",
    "#                        NEGATIVE_IMGS_TRAIN_FOLDER, \\\n",
    "#                        NEGATIVE_IMGS_VALIDATION_FOLDER]\n",
    "# for current_folder in folder_collections:\n",
    "#     shutil.rmtree(current_folder)\n",
    "#     os.makedirs(current_folder)\n",
    "\n",
    "#save and copy\n",
    "def copy_train_validation_image(image_index, source_image_folder, des_image_folder):\n",
    "    source_path = os.path.join(source_image_folder, str(image_index) + '.jpg')\n",
    "    paste_path = os.path.join(des_image_folder, str(image_index) + '.jpg')\n",
    "#     print(image)\n",
    "    shutil.copyfile(source_path, paste_path)\n",
    "    \n",
    "for i in positive_1_train_indices:\n",
    "    copy_train_validation_image(i, POSITIVE_1_IMGS_FOLDER, POSITIVE_1_IMGS_TRAIN_FOLDER)\n",
    "for i in positive_1_validation_indices:\n",
    "    copy_train_validation_image(i, POSITIVE_1_IMGS_FOLDER, POSITIVE_1_IMGS_VALIDATION_FOLDER)\n",
    "for i in positive_2_train_indices:\n",
    "    copy_train_validation_image(i, POSITIVE_2_IMGS_FOLDER, POSITIVE_2_IMGS_TRAIN_FOLDER)\n",
    "for i in positive_2_validation_indices:\n",
    "    copy_train_validation_image(i, POSITIVE_2_IMGS_FOLDER, POSITIVE_2_IMGS_VALIDATION_FOLDER)\n",
    "for i in negative_train_indices:\n",
    "    copy_train_validation_image(i, NEGATIVE_IMGS_FOLDER, NEGATIVE_IMGS_TRAIN_FOLDER)\n",
    "for i in negative_validation_indices:\n",
    "    copy_train_validation_image(i, NEGATIVE_IMGS_FOLDER, NEGATIVE_IMGS_VALIDATION_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# image preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import PIL.Image\n",
    "import glob, os, shutil\n",
    "POSITIVE_1_IMGS_FOLDER = r'C:\\Users\\wiqwe\\Desktop\\上交科研\\selected_positive_#1_imgs'\n",
    "POSITIVE_1_IMGS_TRAIN_FOLDER = r'C:\\Users\\wiqwe\\Desktop\\上交科研\\selected_positive_#1_imgs_train'\n",
    "POSITIVE_1_IMGS_VALIDATION_FOLDER = r'C:\\Users\\wiqwe\\Desktop\\上交科研\\selected_positive_#1_imgs_validation'\n",
    "POSITIVE_2_IMGS_FOLDER = r'C:\\Users\\wiqwe\\Desktop\\上交科研\\selected_positive_#2_imgs'\n",
    "POSITIVE_2_IMGS_TRAIN_FOLDER = r'C:\\Users\\wiqwe\\Desktop\\上交科研\\selected_positive_#2_imgs_train'\n",
    "POSITIVE_2_IMGS_VALIDATION_FOLDER = r'C:\\Users\\wiqwe\\Desktop\\上交科研\\selected_positive_#2_imgs_validation'\n",
    "NEGATIVE_IMGS_FOLDER = r'C:\\Users\\wiqwe\\Desktop\\上交科研\\selected_negative_imgs'\n",
    "NEGATIVE_IMGS_TRAIN_FOLDER = r'C:\\Users\\wiqwe\\Desktop\\上交科研\\selected_negative_imgs_train'\n",
    "NEGATIVE_IMGS_VALIDATION_FOLDER = r'C:\\Users\\wiqwe\\Desktop\\上交科研\\selected_negative_imgs_validation'\n",
    "\n",
    "train_data = []\n",
    "train_label = []\n",
    "validation_data = []\n",
    "validation_label = []\n",
    "\n",
    "folder_collections = [POSITIVE_1_IMGS_TRAIN_FOLDER, \\\n",
    "                       POSITIVE_1_IMGS_VALIDATION_FOLDER, \\\n",
    "                       POSITIVE_2_IMGS_TRAIN_FOLDER,\n",
    "                       POSITIVE_2_IMGS_VALIDATION_FOLDER, \\\n",
    "                       NEGATIVE_IMGS_TRAIN_FOLDER, \\\n",
    "                       NEGATIVE_IMGS_VALIDATION_FOLDER]\n",
    "label_collections = [[0, 1, 0], [0, 1, 0], [0, 0, 1], [0, 0, 1], [1, 0, 0], [1, 0, 0]]\n",
    "    \n",
    "for folder_index, current_folder in enumerate(folder_collections):\n",
    "    for img in glob.glob(os.path.join(current_folder ,'*')):\n",
    "        im = PIL.Image.open(img)\n",
    "        # im = im.convert('LA')\n",
    "        im = im.resize((224,224))\n",
    "        im = np.array(im)\n",
    "        im = (im / 255.0) - 1.0\n",
    "    #     im_roll = np.rollaxis(im, 2, 0)\n",
    "    #     assert (im[:,:,0] == im_roll[0,:,:]).all()\n",
    "    #     assert (im[:,:,1] == im_roll[1,:,:]).all()\n",
    "    #     assert (im[:,:,2] == im_roll[2,:,:]).all()\n",
    "        if 'train' in current_folder:\n",
    "            train_data.append(np.array(im))\n",
    "            train_label.append(label_collections[folder_index])\n",
    "        elif 'validation' in current_folder:\n",
    "            validation_data.append(np.array(im))\n",
    "            validation_label.append(label_collections[folder_index])\n",
    "        else:\n",
    "            print(current_folder)\n",
    "            raise TypeError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3318 (224, 224, 3) 3318\n",
      "366 (224, 224, 3) 366\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data), train_data[0].shape, len(train_label))\n",
    "print(len(validation_data), validation_data[0].shape, len(validation_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recovered_img = ((train_data[0]+1)*255).astype(np.uint8)\n",
    "print(recovered_img.shape)\n",
    "PIL.Image.fromarray(recovered_img).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3318, 224, 224, 3) (3318, 3) (366, 224, 224, 3) (366, 3)\n"
     ]
    }
   ],
   "source": [
    "train_data = np.stack(train_data, axis=0)\n",
    "train_label = np.array(train_label)\n",
    "validation_data = np.stack(validation_data, axis=0)\n",
    "validation_label = np.array(validation_label)\n",
    "print(train_data.shape, train_label.shape, validation_data.shape, validation_label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Resnet 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_50 = ResnetBuilder.build_resnet_50((3,224,224), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(lr=0.001, amsgrad=True, decay=0.00005)\n",
    "resnet_50.compile(optimizer, loss=keras.losses.categorical_crossentropy, metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callback function to save model every 10 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate schedular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter searching for resnet 50, train for 100 epoch\n",
    "# lr -> {0.001, 0.005, 0.0005}\n",
    "# decay -> {0.00001, 0.0001, 0.0005}\n",
    "# l2 - > {1e-3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3318 samples, validate on 366 samples\n",
      "Epoch 1/50\n",
      "3318/3318 [==============================] - 468s 141ms/step - loss: 25.1410 - categorical_accuracy: 0.8382 - val_loss: 10.8607 - val_categorical_accuracy: 0.5683\n",
      "Epoch 2/50\n",
      "3318/3318 [==============================] - 45s 14ms/step - loss: 5.9603 - categorical_accuracy: 0.8927 - val_loss: 4.1703 - val_categorical_accuracy: 0.7459\n",
      "Epoch 3/50\n",
      "3318/3318 [==============================] - 45s 14ms/step - loss: 2.8307 - categorical_accuracy: 0.9075 - val_loss: 3.5253 - val_categorical_accuracy: 0.3880\n",
      "Epoch 4/50\n",
      "3318/3318 [==============================] - 45s 14ms/step - loss: 1.9418 - categorical_accuracy: 0.9147 - val_loss: 2.1867 - val_categorical_accuracy: 0.6038\n",
      "Epoch 5/50\n",
      "3318/3318 [==============================] - 45s 14ms/step - loss: 1.4978 - categorical_accuracy: 0.9283 - val_loss: 1.7504 - val_categorical_accuracy: 0.6639\n",
      "Epoch 6/50\n",
      "3318/3318 [==============================] - 45s 14ms/step - loss: 1.2413 - categorical_accuracy: 0.9394 - val_loss: 1.6352 - val_categorical_accuracy: 0.6475\n",
      "Epoch 7/50\n",
      "3318/3318 [==============================] - 45s 14ms/step - loss: 1.0779 - categorical_accuracy: 0.9436 - val_loss: 2.3760 - val_categorical_accuracy: 0.4344\n",
      "Epoch 8/50\n",
      "3318/3318 [==============================] - 45s 14ms/step - loss: 1.0166 - categorical_accuracy: 0.9385 - val_loss: 1.2301 - val_categorical_accuracy: 0.7978\n",
      "Epoch 9/50\n",
      "3318/3318 [==============================] - 45s 14ms/step - loss: 0.9042 - categorical_accuracy: 0.9403 - val_loss: 2.1942 - val_categorical_accuracy: 0.3470\n",
      "Epoch 10/50\n",
      "3318/3318 [==============================] - 45s 14ms/step - loss: 0.8536 - categorical_accuracy: 0.9497 - val_loss: 1.4641 - val_categorical_accuracy: 0.5820\n",
      "Epoch 11/50\n",
      "3318/3318 [==============================] - 45s 14ms/step - loss: 0.7308 - categorical_accuracy: 0.9554 - val_loss: 2.4544 - val_categorical_accuracy: 0.1202\n",
      "Epoch 12/50\n",
      "3318/3318 [==============================] - 45s 14ms/step - loss: 0.6402 - categorical_accuracy: 0.9611 - val_loss: 2.5436 - val_categorical_accuracy: 0.1257\n",
      "Epoch 13/50\n",
      "3318/3318 [==============================] - 45s 14ms/step - loss: 0.6074 - categorical_accuracy: 0.9632 - val_loss: 1.0252 - val_categorical_accuracy: 0.7842\n",
      "Epoch 14/50\n",
      "3318/3318 [==============================] - 45s 14ms/step - loss: 0.6567 - categorical_accuracy: 0.9563 - val_loss: 4.6767 - val_categorical_accuracy: 0.4180\n",
      "Epoch 15/50\n",
      "3318/3318 [==============================] - 46s 14ms/step - loss: 0.5807 - categorical_accuracy: 0.9569 - val_loss: 8.1945 - val_categorical_accuracy: 0.1148\n",
      "Epoch 16/50\n",
      "3318/3318 [==============================] - 46s 14ms/step - loss: 0.5580 - categorical_accuracy: 0.9599 - val_loss: 2.9551 - val_categorical_accuracy: 0.3607\n",
      "Epoch 17/50\n",
      "3318/3318 [==============================] - 46s 14ms/step - loss: 0.5167 - categorical_accuracy: 0.9581 - val_loss: 1.9422 - val_categorical_accuracy: 0.3880\n",
      "Epoch 18/50\n",
      "3318/3318 [==============================] - 46s 14ms/step - loss: 0.4712 - categorical_accuracy: 0.9653 - val_loss: 1.7065 - val_categorical_accuracy: 0.4672\n",
      "Epoch 19/50\n",
      "3318/3318 [==============================] - 47s 14ms/step - loss: 0.4626 - categorical_accuracy: 0.9647 - val_loss: 3.3258 - val_categorical_accuracy: 0.6421\n",
      "Epoch 20/50\n",
      "3318/3318 [==============================] - 47s 14ms/step - loss: 0.4451 - categorical_accuracy: 0.9656 - val_loss: 1.2039 - val_categorical_accuracy: 0.5437\n",
      "Epoch 21/50\n",
      "3318/3318 [==============================] - 46s 14ms/step - loss: 0.4049 - categorical_accuracy: 0.9720 - val_loss: 3.9960 - val_categorical_accuracy: 0.1148\n",
      "Epoch 22/50\n",
      "3318/3318 [==============================] - 45s 14ms/step - loss: 0.4517 - categorical_accuracy: 0.9623 - val_loss: 2.1110 - val_categorical_accuracy: 0.3934\n",
      "Epoch 23/50\n",
      "3318/3318 [==============================] - 46s 14ms/step - loss: 0.3861 - categorical_accuracy: 0.9738 - val_loss: 1.6060 - val_categorical_accuracy: 0.4754\n",
      "Epoch 24/50\n",
      "3318/3318 [==============================] - 46s 14ms/step - loss: 0.3373 - categorical_accuracy: 0.9762 - val_loss: 1.2050 - val_categorical_accuracy: 0.5273\n",
      "Epoch 25/50\n",
      "3318/3318 [==============================] - 47s 14ms/step - loss: 0.4085 - categorical_accuracy: 0.9684 - val_loss: 5.1229 - val_categorical_accuracy: 0.2951\n",
      "Epoch 26/50\n",
      "3318/3318 [==============================] - 47s 14ms/step - loss: 0.3613 - categorical_accuracy: 0.9717 - val_loss: 1.1031 - val_categorical_accuracy: 0.5246\n",
      "Epoch 27/50\n",
      "3318/3318 [==============================] - 47s 14ms/step - loss: 0.3777 - categorical_accuracy: 0.9653 - val_loss: 0.9527 - val_categorical_accuracy: 0.7295\n",
      "Epoch 28/50\n",
      "3318/3318 [==============================] - 46s 14ms/step - loss: 0.3557 - categorical_accuracy: 0.9744 - val_loss: 1.2607 - val_categorical_accuracy: 0.6230\n",
      "Epoch 29/50\n",
      "3318/3318 [==============================] - 47s 14ms/step - loss: 0.3695 - categorical_accuracy: 0.9650 - val_loss: 0.6279 - val_categorical_accuracy: 0.8579\n",
      "Epoch 30/50\n",
      "3318/3318 [==============================] - 46s 14ms/step - loss: 0.2892 - categorical_accuracy: 0.9837 - val_loss: 1.4965 - val_categorical_accuracy: 0.4945\n",
      "Epoch 31/50\n",
      "1440/3318 [============>.................] - ETA: 24s - loss: 0.2592 - categorical_accuracy: 0.9903"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-1fe2fb91b9a0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresnet_50\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "resnet_50.fit(train_data, train_label, epochs=50, batch_size=32, validation_data=(validation_data, validation_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# keras Resnet definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import six\n",
    "\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.layers import (\n",
    "\n",
    "    Input,\n",
    "\n",
    "    Activation,\n",
    "\n",
    "    Dense,\n",
    "\n",
    "    Flatten\n",
    "\n",
    ")\n",
    "\n",
    "from keras.layers.convolutional import (\n",
    "\n",
    "    Conv2D,\n",
    "\n",
    "    MaxPooling2D,\n",
    "\n",
    "    AveragePooling2D\n",
    "\n",
    ")\n",
    "\n",
    "from keras.layers.merge import add\n",
    "\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "from keras.regularizers import l2\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _bn_relu(input):\n",
    "\n",
    "    \"\"\"Helper to build a BN -> relu block\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    norm = BatchNormalization(axis=CHANNEL_AXIS)(input)\n",
    "\n",
    "    return Activation(\"relu\")(norm)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _conv_bn_relu(**conv_params):\n",
    "\n",
    "    \"\"\"Helper to build a conv -> BN -> relu block\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    filters = conv_params[\"filters\"]\n",
    "\n",
    "    kernel_size = conv_params[\"kernel_size\"]\n",
    "\n",
    "    strides = conv_params.setdefault(\"strides\", (1, 1))\n",
    "\n",
    "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
    "\n",
    "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
    "\n",
    "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-3))\n",
    "\n",
    "\n",
    "\n",
    "    def f(input):\n",
    "\n",
    "        conv = Conv2D(filters=filters, kernel_size=kernel_size,\n",
    "\n",
    "                      strides=strides, padding=padding,\n",
    "\n",
    "                      kernel_initializer=kernel_initializer,\n",
    "\n",
    "                      kernel_regularizer=kernel_regularizer)(input)\n",
    "\n",
    "        return _bn_relu(conv)\n",
    "\n",
    "\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _bn_relu_conv(**conv_params):\n",
    "\n",
    "    \"\"\"Helper to build a BN -> relu -> conv block.\n",
    "\n",
    "    This is an improved scheme proposed in http://arxiv.org/pdf/1603.05027v2.pdf\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    filters = conv_params[\"filters\"]\n",
    "\n",
    "    kernel_size = conv_params[\"kernel_size\"]\n",
    "\n",
    "    strides = conv_params.setdefault(\"strides\", (1, 1))\n",
    "\n",
    "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
    "\n",
    "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
    "\n",
    "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-3))\n",
    "\n",
    "\n",
    "\n",
    "    def f(input):\n",
    "\n",
    "        activation = _bn_relu(input)\n",
    "\n",
    "        return Conv2D(filters=filters, kernel_size=kernel_size,\n",
    "\n",
    "                      strides=strides, padding=padding,\n",
    "\n",
    "                      kernel_initializer=kernel_initializer,\n",
    "\n",
    "                      kernel_regularizer=kernel_regularizer)(activation)\n",
    "\n",
    "\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _shortcut(input, residual):\n",
    "\n",
    "    \"\"\"Adds a shortcut between input and residual block and merges them with \"sum\"\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Expand channels of shortcut to match residual.\n",
    "\n",
    "    # Stride appropriately to match residual (width, height)\n",
    "\n",
    "    # Should be int if network architecture is correctly configured.\n",
    "\n",
    "    input_shape = K.int_shape(input)\n",
    "\n",
    "    residual_shape = K.int_shape(residual)\n",
    "\n",
    "    stride_width = int(round(input_shape[ROW_AXIS] / residual_shape[ROW_AXIS]))\n",
    "\n",
    "    stride_height = int(round(input_shape[COL_AXIS] / residual_shape[COL_AXIS]))\n",
    "\n",
    "    equal_channels = input_shape[CHANNEL_AXIS] == residual_shape[CHANNEL_AXIS]\n",
    "\n",
    "\n",
    "\n",
    "    shortcut = input\n",
    "\n",
    "    # 1 X 1 conv if shape is different. Else identity.\n",
    "\n",
    "    if stride_width > 1 or stride_height > 1 or not equal_channels:\n",
    "\n",
    "        shortcut = Conv2D(filters=residual_shape[CHANNEL_AXIS],\n",
    "\n",
    "                          kernel_size=(1, 1),\n",
    "\n",
    "                          strides=(stride_width, stride_height),\n",
    "\n",
    "                          padding=\"valid\",\n",
    "\n",
    "                          kernel_initializer=\"he_normal\",\n",
    "\n",
    "                          kernel_regularizer=l2(0.001))(input)\n",
    "\n",
    "\n",
    "\n",
    "    return add([shortcut, residual])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _residual_block(block_function, filters, repetitions, is_first_layer=False):\n",
    "\n",
    "    \"\"\"Builds a residual block with repeating bottleneck blocks.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def f(input):\n",
    "\n",
    "        for i in range(repetitions):\n",
    "\n",
    "            init_strides = (1, 1)\n",
    "\n",
    "            if i == 0 and not is_first_layer:\n",
    "\n",
    "                init_strides = (2, 2)\n",
    "\n",
    "            input = block_function(filters=filters, init_strides=init_strides,\n",
    "\n",
    "                                   is_first_block_of_first_layer=(is_first_layer and i == 0))(input)\n",
    "\n",
    "        return input\n",
    "\n",
    "\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def basic_block(filters, init_strides=(1, 1), is_first_block_of_first_layer=False):\n",
    "\n",
    "    \"\"\"Basic 3 X 3 convolution blocks for use on resnets with layers <= 34.\n",
    "\n",
    "    Follows improved proposed scheme in http://arxiv.org/pdf/1603.05027v2.pdf\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def f(input):\n",
    "\n",
    "\n",
    "\n",
    "        if is_first_block_of_first_layer:\n",
    "\n",
    "            # don't repeat bn->relu since we just did bn->relu->maxpool\n",
    "\n",
    "            conv1 = Conv2D(filters=filters, kernel_size=(3, 3),\n",
    "\n",
    "                           strides=init_strides,\n",
    "\n",
    "                           padding=\"same\",\n",
    "\n",
    "                           kernel_initializer=\"he_normal\",\n",
    "\n",
    "                           kernel_regularizer=l2(1e-3))(input)\n",
    "\n",
    "        else:\n",
    "\n",
    "            conv1 = _bn_relu_conv(filters=filters, kernel_size=(3, 3),\n",
    "\n",
    "                                  strides=init_strides)(input)\n",
    "\n",
    "\n",
    "\n",
    "        residual = _bn_relu_conv(filters=filters, kernel_size=(3, 3))(conv1)\n",
    "\n",
    "        return _shortcut(input, residual)\n",
    "\n",
    "\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def bottleneck(filters, init_strides=(1, 1), is_first_block_of_first_layer=False):\n",
    "\n",
    "    \"\"\"Bottleneck architecture for > 34 layer resnet.\n",
    "\n",
    "    Follows improved proposed scheme in http://arxiv.org/pdf/1603.05027v2.pdf\n",
    "\n",
    "\n",
    "\n",
    "    Returns:\n",
    "\n",
    "        A final conv layer of filters * 4\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def f(input):\n",
    "\n",
    "\n",
    "\n",
    "        if is_first_block_of_first_layer:\n",
    "\n",
    "            # don't repeat bn->relu since we just did bn->relu->maxpool\n",
    "\n",
    "            conv_1_1 = Conv2D(filters=filters, kernel_size=(1, 1),\n",
    "\n",
    "                              strides=init_strides,\n",
    "\n",
    "                              padding=\"same\",\n",
    "\n",
    "                              kernel_initializer=\"he_normal\",\n",
    "\n",
    "                              kernel_regularizer=l2(1e-3))(input)\n",
    "\n",
    "        else:\n",
    "\n",
    "            conv_1_1 = _bn_relu_conv(filters=filters, kernel_size=(1, 1),\n",
    "\n",
    "                                     strides=init_strides)(input)\n",
    "\n",
    "\n",
    "\n",
    "        conv_3_3 = _bn_relu_conv(filters=filters, kernel_size=(3, 3))(conv_1_1)\n",
    "\n",
    "        residual = _bn_relu_conv(filters=filters * 4, kernel_size=(1, 1))(conv_3_3)\n",
    "\n",
    "        return _shortcut(input, residual)\n",
    "\n",
    "\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _handle_dim_ordering():\n",
    "\n",
    "    global ROW_AXIS\n",
    "\n",
    "    global COL_AXIS\n",
    "\n",
    "    global CHANNEL_AXIS\n",
    "\n",
    "    if K.image_dim_ordering() == 'tf':\n",
    "\n",
    "        ROW_AXIS = 1\n",
    "\n",
    "        COL_AXIS = 2\n",
    "\n",
    "        CHANNEL_AXIS = 3\n",
    "\n",
    "    else:\n",
    "\n",
    "        CHANNEL_AXIS = 1\n",
    "\n",
    "        ROW_AXIS = 2\n",
    "\n",
    "        COL_AXIS = 3\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _get_block(identifier):\n",
    "\n",
    "    if isinstance(identifier, six.string_types):\n",
    "\n",
    "        res = globals().get(identifier)\n",
    "\n",
    "        if not res:\n",
    "\n",
    "            raise ValueError('Invalid {}'.format(identifier))\n",
    "\n",
    "        return res\n",
    "\n",
    "    return identifier\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ResnetBuilder(object):\n",
    "\n",
    "    @staticmethod\n",
    "\n",
    "    def build(input_shape, num_outputs, block_fn, repetitions):\n",
    "\n",
    "        \"\"\"Builds a custom ResNet like architecture.\n",
    "\n",
    "\n",
    "\n",
    "        Args:\n",
    "\n",
    "            input_shape: The input shape in the form (nb_channels, nb_rows, nb_cols)\n",
    "\n",
    "            num_outputs: The number of outputs at final softmax layer\n",
    "\n",
    "            block_fn: The block function to use. This is either `basic_block` or `bottleneck`.\n",
    "\n",
    "                The original paper used basic_block for layers < 50\n",
    "\n",
    "            repetitions: Number of repetitions of various block units.\n",
    "\n",
    "                At each block unit, the number of filters are doubled and the input size is halved\n",
    "\n",
    "\n",
    "\n",
    "        Returns:\n",
    "\n",
    "            The keras `Model`.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        _handle_dim_ordering()\n",
    "\n",
    "        if len(input_shape) != 3:\n",
    "\n",
    "            raise Exception(\"Input shape should be a tuple (nb_channels, nb_rows, nb_cols)\")\n",
    "\n",
    "\n",
    "\n",
    "        # Permute dimension order if necessary\n",
    "\n",
    "        if K.image_dim_ordering() == 'tf':\n",
    "\n",
    "            input_shape = (input_shape[1], input_shape[2], input_shape[0])\n",
    "\n",
    "\n",
    "\n",
    "        # Load function from str if needed.\n",
    "\n",
    "        block_fn = _get_block(block_fn)\n",
    "\n",
    "\n",
    "\n",
    "        input = Input(shape=input_shape)\n",
    "\n",
    "        conv1 = _conv_bn_relu(filters=64, kernel_size=(7, 7), strides=(2, 2))(input)\n",
    "\n",
    "        pool1 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding=\"same\")(conv1)\n",
    "\n",
    "\n",
    "\n",
    "        block = pool1\n",
    "\n",
    "        filters = 64\n",
    "\n",
    "        for i, r in enumerate(repetitions):\n",
    "\n",
    "            block = _residual_block(block_fn, filters=filters, repetitions=r, is_first_layer=(i == 0))(block)\n",
    "\n",
    "            filters *= 2\n",
    "\n",
    "\n",
    "\n",
    "        # Last activation\n",
    "\n",
    "        block = _bn_relu(block)\n",
    "\n",
    "\n",
    "\n",
    "        # Classifier block\n",
    "\n",
    "        block_shape = K.int_shape(block)\n",
    "\n",
    "        pool2 = AveragePooling2D(pool_size=(block_shape[ROW_AXIS], block_shape[COL_AXIS]),\n",
    "\n",
    "                                 strides=(1, 1))(block)\n",
    "\n",
    "        flatten1 = Flatten()(pool2)\n",
    "\n",
    "        dense = Dense(units=num_outputs, kernel_initializer=\"he_normal\",\n",
    "\n",
    "                      activation=\"softmax\")(flatten1)\n",
    "\n",
    "\n",
    "\n",
    "        model = Model(inputs=input, outputs=dense)\n",
    "\n",
    "        return model\n",
    "\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "\n",
    "    def build_resnet_18(input_shape, num_outputs):\n",
    "\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, basic_block, [2, 2, 2, 2])\n",
    "\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "\n",
    "    def build_resnet_34(input_shape, num_outputs):\n",
    "\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, basic_block, [3, 4, 6, 3])\n",
    "\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "\n",
    "    def build_resnet_50(input_shape, num_outputs):\n",
    "\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 4, 6, 3])\n",
    "\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "\n",
    "    def build_resnet_101(input_shape, num_outputs):\n",
    "\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 4, 23, 3])\n",
    "\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "\n",
    "    def build_resnet_152(input_shape, num_outputs):\n",
    "\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 8, 36, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
